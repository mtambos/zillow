{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "%pylab inline\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train_2016_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'parcelid': int,\n",
    "    'airconditioningtypeid': str,\n",
    "    'architecturalstyletypeid': str,\n",
    "    'buildingclasstypeid': str,\n",
    "    'buildingqualitytypeid': str,\n",
    "    'decktypeid': str,\n",
    "    'heatingorsystemtypeid': str,\n",
    "    'pooltypeid10': str,\n",
    "    'pooltypeid2': str,\n",
    "    'pooltypeid7': str,\n",
    "    'regionidcity': str,\n",
    "    'regionidcounty': str,\n",
    "    'regionidneighborhood': str,\n",
    "    'regionidzip': str,\n",
    "    'typeconstructiontypeid': str,\n",
    "    'hashottuborspa': str,\n",
    "    'propertycountylandusecode': str,\n",
    "    'propertylandusetypeid': str,\n",
    "    'propertyzoningdesc': str,\n",
    "    'rawcensustractandblock': str,\n",
    "    'fireplaceflag': str,\n",
    "    'taxdelinquencyflag': str,\n",
    "    'censustractandblock': str,\n",
    "}\n",
    "\n",
    "props_df = pd.read_csv('./data/properties_2016.csv', dtype=dtypes)\n",
    "\n",
    "dtypes.update({\n",
    "    'fireplacecnt': int,\n",
    "    'fullbathcnt': int,\n",
    "    'garagecarcnt': int,\n",
    "    'poolcnt': int,\n",
    "    'threequarterbathnbr': int,\n",
    "    'unitcnt': int,\n",
    "    'yearbuilt': int,\n",
    "    'numberofstories': int,\n",
    "    'structuretaxvaluedollarcnt': int,\n",
    "    'taxvaluedollarcnt': int,\n",
    "    'landtaxvaluedollarcnt': int,\n",
    "    'taxdelinquencyyear': int,\n",
    "    'roomcnt': int,\n",
    "    'bedroomcnt': int,\n",
    "    'assessmentyear': int,\n",
    "    'fips': int,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11016594</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122754.0</td>\n",
       "      <td>360170.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>237416.0</td>\n",
       "      <td>6735.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60371066461001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14366692</td>\n",
       "      <td>-0.1684</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346458.0</td>\n",
       "      <td>585529.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>239071.0</td>\n",
       "      <td>10153.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12098116</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61994.0</td>\n",
       "      <td>119906.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>57912.0</td>\n",
       "      <td>11484.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60374638003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12643413</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171518.0</td>\n",
       "      <td>244880.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>73362.0</td>\n",
       "      <td>3048.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60372963002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14432541</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169574.0</td>\n",
       "      <td>434551.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>264977.0</td>\n",
       "      <td>5488.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60590423381006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  logerror transactiondate airconditioningtypeid  \\\n",
       "0  11016594    0.0276      2016-01-01                     1   \n",
       "1  14366692   -0.1684      2016-01-01                   NaN   \n",
       "2  12098116   -0.0040      2016-01-01                     1   \n",
       "3  12643413    0.0218      2016-01-02                     1   \n",
       "4  14432541   -0.0050      2016-01-02                   NaN   \n",
       "\n",
       "  architecturalstyletypeid  basementsqft  bathroomcnt  bedroomcnt  \\\n",
       "0                      NaN           NaN          2.0         3.0   \n",
       "1                      NaN           NaN          3.5         4.0   \n",
       "2                      NaN           NaN          3.0         2.0   \n",
       "3                      NaN           NaN          2.0         2.0   \n",
       "4                      NaN           NaN          2.5         4.0   \n",
       "\n",
       "  buildingclasstypeid buildingqualitytypeid         ...           \\\n",
       "0                 NaN                     4         ...            \n",
       "1                 NaN                   NaN         ...            \n",
       "2                 NaN                     4         ...            \n",
       "3                 NaN                     4         ...            \n",
       "4                 NaN                   NaN         ...            \n",
       "\n",
       "   numberofstories fireplaceflag  structuretaxvaluedollarcnt  \\\n",
       "0              NaN           NaN                    122754.0   \n",
       "1              NaN           NaN                    346458.0   \n",
       "2              NaN           NaN                     61994.0   \n",
       "3              NaN           NaN                    171518.0   \n",
       "4              2.0           NaN                    169574.0   \n",
       "\n",
       "   taxvaluedollarcnt  assessmentyear  landtaxvaluedollarcnt  taxamount  \\\n",
       "0           360170.0          2015.0               237416.0    6735.88   \n",
       "1           585529.0          2015.0               239071.0   10153.02   \n",
       "2           119906.0          2015.0                57912.0   11484.48   \n",
       "3           244880.0          2015.0                73362.0    3048.74   \n",
       "4           434551.0          2015.0               264977.0    5488.96   \n",
       "\n",
       "   taxdelinquencyflag  taxdelinquencyyear  censustractandblock  \n",
       "0                 NaN                 NaN       60371066461001  \n",
       "1                 NaN                 NaN                  NaN  \n",
       "2                 NaN                 NaN       60374638003004  \n",
       "3                 NaN                 NaN       60372963002002  \n",
       "4                 NaN                 NaN       60590423381006  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.merge(props_df, on='parcelid', how='left')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transf(df):\n",
    "    if 'structuretaxvaluedollarcnt' in df.columns:\n",
    "        df.loc[:, 'structuretaxvaluedollarcnt'] = np.log1p(df.structuretaxvaluedollarcnt).copy()\n",
    "    if 'taxvaluedollarcnt' in df.columns:\n",
    "        df.loc[:, 'taxvaluedollarcnt'] = np.log1p(df.taxvaluedollarcnt).copy()\n",
    "    if 'calculatedfinishedsquarefeet' in df.columns:\n",
    "        df.loc[:, 'calculatedfinishedsquarefeet'] = np.log1p(df.calculatedfinishedsquarefeet).copy()\n",
    "    if 'lotsizesquarefeet' in df.columns:\n",
    "        df.loc[:, 'lotsizesquarefeet'] = np.log1p(df.lotsizesquarefeet).copy()\n",
    "    if 'finishedsquarefeet12' in df.columns:\n",
    "        df.loc[:, 'finishedsquarefeet12'] = np.log1p(df.finishedsquarefeet12).copy()\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df, rejected_cols=[], l_perc=1, u_perc=99, l_perc_val=None, u_perc_val=None,\n",
    "               month_agg=None):\n",
    "    drop_cols = set(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc',\n",
    "                     'propertycountylandusecode']+rejected_cols)\n",
    "    df = df.copy()\n",
    "    df['latitude'] = df.latitude / 1e6\n",
    "    df['longitude'] = df.longitude / 1e6\n",
    "    if 'transactiondate' in df.columns and month_agg is None:\n",
    "        df['transactiondate'] = pd.to_datetime(df.transactiondate)\n",
    "        df['transactionmonth'] = df.transactiondate.dt.month\n",
    "        month_agg = df[['transactionmonth', 'logerror']].groupby('transactionmonth').mean()\n",
    "        for m, v in month_agg.iterrows():\n",
    "            df.loc[df.transactionmonth == m, 'transactionmonthavglogerr'] = v.logerror\n",
    "    else:\n",
    "        df['transactionmonth'] = month_agg[0]\n",
    "        df['transactionmonthavglogerr'] = month_agg[1]\n",
    "    \n",
    "    # From https://www.kaggle.com/nikunjm88/creating-additional-features\n",
    "    #life of property\n",
    "    df['N-life'] = 2018 - df['yearbuilt']\n",
    "\n",
    "    #proportion of living area\n",
    "    df['N-LivingAreaProp'] = df['calculatedfinishedsquarefeet']/df['lotsizesquarefeet']\n",
    "    df['N-LivingAreaProp2'] = df['N-LivingAreaProp']**2\n",
    "    df['N-LivingAreaProp3'] = df['N-LivingAreaProp']**3\n",
    "    df['N-LivingAreaProp-2'] = df['finishedsquarefeet12']/df['finishedsquarefeet15']\n",
    "\n",
    "    #Amout of extra space\n",
    "    df['N-ExtraSpace'] = df['lotsizesquarefeet'] - df['calculatedfinishedsquarefeet'] \n",
    "    df['N-ExtraSpace-2'] = df['finishedsquarefeet15'] - df['finishedsquarefeet12'] \n",
    "\n",
    "    #Total number of rooms\n",
    "    df['N-TotalRooms'] = df['bathroomcnt']*df['bedroomcnt']\n",
    "\n",
    "    #Average room size\n",
    "    df['N-AvRoomSize'] = df['calculatedfinishedsquarefeet']/df['roomcnt'] \n",
    "\n",
    "    # Number of Extra rooms\n",
    "    df['N-ExtraRooms'] = df['roomcnt'] - df['N-TotalRooms'] \n",
    "\n",
    "    #Ratio of the built structure value to land area\n",
    "    df['N-ValueProp'] = df['structuretaxvaluedollarcnt']/df['landtaxvaluedollarcnt']\n",
    "\n",
    "    df['N-ValueProp2'] = df['N-ValueProp']**2\n",
    "    df['N-ValueProp3'] = df['N-ValueProp']**3\n",
    "    \n",
    "    #Does property have a garage, pool or hot tub and AC?\n",
    "    df['N-GarPoolAC'] = ((df['garagecarcnt'] > 0) &\n",
    "                         (df['pooltypeid10'] != '0') &\n",
    "                         (df['airconditioningtypeid'] != '5'))*1 \n",
    "    drop_cols.add('garagecarcnt')\n",
    "    \n",
    "    df[\"N-location\"] = df[\"latitude\"] + df[\"longitude\"]\n",
    "    df[\"N-location-2\"] = df[\"latitude\"] * df[\"longitude\"]\n",
    "    df[\"N-location-2round\"] = df[\"N-location-2\"].round(-4)\n",
    "\n",
    "    df[\"N-latitude-round\"] = df[\"latitude\"].round(-4)\n",
    "    df[\"N-longitude-round\"] = df[\"longitude\"].round(-4)\n",
    "\n",
    "    #Ratio of tax of property over parcel\n",
    "    df['N-ValueRatio'] = df['taxvaluedollarcnt']/df['taxamount']\n",
    "    df['N-ValueRatio2'] = df['N-ValueRatio']**2\n",
    "    df['N-ValueRatio3'] = df['N-ValueRatio']**3\n",
    "\n",
    "    #TotalTaxScore\n",
    "    df['N-TaxScore'] = df['taxvaluedollarcnt']*df['taxamount']\n",
    "    df['N-TaxScore2'] = df['N-TaxScore']**2\n",
    "    df['N-TaxScore3'] = df['N-TaxScore']**3\n",
    "    \n",
    "    #polnomials of tax delinquency year\n",
    "    df[\"N-taxdelinquencyyear-2\"] = df[\"taxdelinquencyyear\"] ** 2\n",
    "    df[\"N-taxdelinquencyyear-3\"] = df[\"taxdelinquencyyear\"] ** 3\n",
    "\n",
    "    #Length of time since unpaid taxes\n",
    "    df['N-life'] = 2018 - df['taxdelinquencyyear']\n",
    "\n",
    "    #Number of properties in the zip\n",
    "    zip_count = df['regionidzip'].value_counts().to_dict()\n",
    "    df['N-zip_count'] = df['regionidzip'].map(zip_count)\n",
    "\n",
    "    #Number of properties in the city\n",
    "    city_count = df['regionidcity'].value_counts().to_dict()\n",
    "    df['N-city_count'] = df['regionidcity'].map(city_count)\n",
    "\n",
    "    #Number of properties in the city\n",
    "    region_count = df['regionidcounty'].value_counts().to_dict()\n",
    "    df['N-county_count'] = df['regionidcounty'].map(city_count)\n",
    "\n",
    "    #Indicator whether it has AC or not\n",
    "    df['N-ACInd'] = (df['airconditioningtypeid']!=5)*1\n",
    "\n",
    "    #Indicator whether it has Heating or not \n",
    "    df['N-HeatInd'] = (df['heatingorsystemtypeid']!=13)*1\n",
    "\n",
    "    #There's 25 different property uses - let's compress them down to 4 categories\n",
    "    df['N-PropType'] = df.propertylandusetypeid.replace({\n",
    "        31 : \"Mixed\",\n",
    "        46 : \"Other\",\n",
    "        47 : \"Mixed\",\n",
    "        246 : \"Mixed\",\n",
    "        247 : \"Mixed\",\n",
    "        248 : \"Mixed\",\n",
    "        260 : \"Home\",\n",
    "        261 : \"Home\",\n",
    "        262 : \"Home\",\n",
    "        263 : \"Home\",\n",
    "        264 : \"Home\",\n",
    "        265 : \"Home\",\n",
    "        266 : \"Home\",\n",
    "        267 : \"Home\",\n",
    "        268 : \"Home\",\n",
    "        269 : \"Not Built\",\n",
    "        270 : \"Home\",\n",
    "        271 : \"Home\",\n",
    "        273 : \"Home\",\n",
    "        274 : \"Other\",\n",
    "        275 : \"Home\",\n",
    "        276 : \"Home\",\n",
    "        279 : \"Home\",\n",
    "        290 : \"Not Built\",\n",
    "        291 : \"Not Built\"\n",
    "    })\n",
    "    drop_cols.add('propertylandusetypeid')\n",
    "\n",
    "\n",
    "    #polnomials of the variable\n",
    "    df[\"N-structuretaxvaluedollarcnt-2\"] = df[\"structuretaxvaluedollarcnt\"] ** 2\n",
    "    df[\"N-structuretaxvaluedollarcnt-3\"] = df[\"structuretaxvaluedollarcnt\"] ** 3\n",
    "\n",
    "    #Average structuretaxvaluedollarcnt by city\n",
    "    group = df.groupby('regionidcity')['structuretaxvaluedollarcnt'].aggregate('mean').to_dict()\n",
    "    df['N-Avg-structuretaxvaluedollarcnt'] = df['regionidcity'].map(group)\n",
    "\n",
    "    #Deviation away from average\n",
    "    df['N-Dev-structuretaxvaluedollarcnt'] = (abs((df['structuretaxvaluedollarcnt'] -\n",
    "                                                   df['N-Avg-structuretaxvaluedollarcnt'])) /\n",
    "                                              df['N-Avg-structuretaxvaluedollarcnt'])\n",
    "\n",
    "    df['fireplaceflag'] = df.fireplaceflag == 'True'\n",
    "    df['taxdelinquencyflag'] = df.taxdelinquencyflag == 'Y'\n",
    "    df['hashottuborspa'] = df.hashottuborspa == 'true'\n",
    "\n",
    "    df['fireplacecnt'] = df.fireplacecnt.fillna(0).astype(int)\n",
    "    df['fullbathcnt'] = df.fullbathcnt.fillna(0).astype(int)\n",
    "    df['garagecarcnt'] = df.garagecarcnt.fillna(0).astype(int)\n",
    "    df['poolcnt'] = df.poolcnt.fillna(0).astype(int)\n",
    "    df['threequarterbathnbr'] = df.threequarterbathnbr.fillna(0).astype(int)\n",
    "    df['unitcnt'] = df.threequarterbathnbr.fillna(0).astype(int)\n",
    "    df['numberofstories'] = df.numberofstories.fillna(0).astype(int)\n",
    "    df['numberofstories'] = df.numberofstories.fillna(0).astype(int)\n",
    "    df['roomcnt'] = df.roomcnt.fillna(0).astype(int)\n",
    "    df['bedroomcnt'] = df.bedroomcnt.fillna(0).astype(int)\n",
    "    df['bedroomcnt'] = df.bedroomcnt.fillna(0).astype(int)\n",
    "\n",
    "    df['fips'] = df.fips.fillna(-1).astype(int)\n",
    "\n",
    "    df['yearbuilt'] = df.yearbuilt.fillna(np.round(df.yearbuilt.mean())).astype(int)\n",
    "    df['taxdelinquencyyear'] = df.taxdelinquencyyear.fillna(\n",
    "        np.round(df.taxdelinquencyyear.mean())\n",
    "    ).astype(int)\n",
    "    df['assessmentyear'] = df.assessmentyear.fillna(\n",
    "        np.round(df.assessmentyear.mean())\n",
    "    ).astype(int)\n",
    "    df['structuretaxvaluedollarcnt'] = df.structuretaxvaluedollarcnt.fillna(\n",
    "        np.round(df.structuretaxvaluedollarcnt.mean())\n",
    "    ).astype(int)\n",
    "    df['taxvaluedollarcnt'] = df.taxvaluedollarcnt.fillna(\n",
    "        np.round(df.taxvaluedollarcnt.mean())\n",
    "    ).astype(int)\n",
    "    df['landtaxvaluedollarcnt'] = df.landtaxvaluedollarcnt.fillna(\n",
    "        np.round(df.landtaxvaluedollarcnt.mean())\n",
    "    ).astype(int)\n",
    "    \n",
    "    # drop columns with std 0\n",
    "    df = df.drop(['buildingclasstypeid', 'pooltypeid10', 'pooltypeid7',\n",
    "                  'storytypeid', 'poolcnt', 'assessmentyear'], axis=1, errors='ignore')\n",
    "\n",
    "    df_cols = df.columns\n",
    "    df.loc[:, df_cols.str.contains('sqft')] = df.loc[:, df_cols.str.contains('sqft')].fillna(0)\n",
    "    \n",
    "    # set nan values in *squarefeet* columns to 0\n",
    "    df.loc[:, df_cols.str.contains('squarefeet')] = df.loc[:, df_cols.str.contains('squarefeet')].fillna(0)\n",
    "\n",
    "    \n",
    "    # fill NaNs in *typeid* columns to -1\n",
    "    df.loc[:, df_cols.str.contains('typeid')] = df.loc[:, df_cols.str.contains('typeid')].fillna(-1)\n",
    "    \n",
    "    # set nan values in *cnt* columns to 0\n",
    "    df.loc[:, df_cols.str.contains('cnt')] = df.loc[:, df_cols.str.contains('cnt')].fillna(0)\n",
    "    \n",
    "    # set NaNs in rest of counts/sums columns to 0\n",
    "    cols = ['calculatedbathnbr', 'poolsizesum', 'threequarterbathnbr', 'numberofstories']\n",
    "    df.loc[:, cols] = df.loc[:, cols].fillna(0)\n",
    "\n",
    "    # set NaNs in rest of id/code columns to 0\n",
    "    cols = ['regionidcity', 'regionidneighborhood', 'regionidzip', 'censustractandblock']\n",
    "    df.loc[:, cols] = df.loc[:, cols].fillna(-1)\n",
    "\n",
    "    # set NaNs in rest of dates columns to mean\n",
    "    cols = ['yearbuilt', 'taxamount', 'taxdelinquencyyear']\n",
    "    df.loc[:, cols] = df.loc[:, cols].fillna(df.loc[:, cols].mean())\n",
    "\n",
    "    drop_cols &= set(df.columns)\n",
    "    X = df.drop(drop_cols, axis=1).copy()\n",
    "    y = None\n",
    "    if 'logerror' in df.columns:\n",
    "        y = df['logerror'].values.copy()\n",
    "        if l_perc_val is None and u_perc_val is None:\n",
    "            l_perc_val, u_perc_val = np.percentile(y, [l_perc, u_perc])\n",
    "        elif l_perc_val is None:\n",
    "            l_perc_val, u_perc_val = np.percentile(y, l_perc)\n",
    "        elif u_perc_val is None:\n",
    "            u_perc_val = np.percentile(y, u_perc)\n",
    "        mask = (y > l_perc_val) & (y < u_perc_val)\n",
    "        y = y[mask]\n",
    "\n",
    "    for c in X.columns:\n",
    "        if X[c].dtype == 'object':\n",
    "            lbl = LabelEncoder()\n",
    "            X[c] = lbl.fit_transform(list(X[c].values))\n",
    "\n",
    "    X = log_transf(X)\n",
    "    X['calculatedfinishedsquarefeet2'] = X['calculatedfinishedsquarefeet']**2\n",
    "    X['calculatedfinishedsquarefeet3'] = X['calculatedfinishedsquarefeet']**3\n",
    "    \n",
    "    if y is not None:\n",
    "        X = X.loc[mask]\n",
    "    \n",
    "    return X, y, l_perc_val, u_perc_val, month_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1, df_test =\\\n",
    "    train_test_split(df_train, test_size=0.2, random_state=0, stratify=np.sign(df_train.logerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01578131],\n",
       "       [ 0.01544458],\n",
       "       [ 0.01091694],\n",
       "       [ 0.00520398],\n",
       "       [ 0.00653953],\n",
       "       [ 0.00834217],\n",
       "       [ 0.01165187],\n",
       "       [ 0.01007382],\n",
       "       [ 0.01688548],\n",
       "       [ 0.01773985],\n",
       "       [ 0.01612922],\n",
       "       [ 0.02328138]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_agg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_cols1 = [\n",
    "    'calculatedbathnbr',\n",
    "    'finishedsquarefeet12',\n",
    "    'finishedsquarefeet13',\n",
    "    'finishedsquarefeet15',\n",
    "    'finishedsquarefeet50',\n",
    "    'finishedsquarefeet6',\n",
    "    'fullbathcnt',\n",
    "    'landtaxvaluedollarcnt',\n",
    "    'taxamount'\n",
    "]\n",
    "X_train, y_train, l_perc_val, u_perc_val, month_agg = preprocess(df_train1, rejected_cols1)\n",
    "X_test = []\n",
    "y_test = []\n",
    "test_transactiondates = pd.to_datetime(df_test.transactiondate)\n",
    "for m, v in month_agg.iterrows():\n",
    "    xx, yy, *_ = preprocess(df_test[test_transactiondates.dt.month == m],\n",
    "                            rejected_cols1, month_agg=(m, v.logerror))\n",
    "    X_test.append(xx)\n",
    "    y_test.append(yy)\n",
    "\n",
    "X_test = pd.concat(X_test)\n",
    "y_test = np.hstack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rejected_cols2 = [\n",
    "    'censustractandblock',\n",
    "    'typeconstructiontypeid',\n",
    "    'unitcnt'\n",
    "]\n",
    "X_train = X_train.drop(rejected_cols2, axis=1)\n",
    "X_test = X_test.drop(rejected_cols2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', colsample_bytree=1, learning_rate=0.03,\n",
       "       max_bin=500, max_depth=-1, min_child_samples=10, min_child_weight=5,\n",
       "       min_split_gain=0, n_estimators=300, nthread=-1, num_leaves=100,\n",
       "       objective='regression_l1', reg_alpha=0, reg_lambda=0, seed=0,\n",
       "       seed =0, silent=False, subsample=1, subsample_for_bin=50000,\n",
       "       subsample_freq=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_params = {\n",
    "    'boosting_type': 'dart',\n",
    "    'colsample_bytree': 1,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_bin': 500,\n",
    "    'n_estimators': 300,\n",
    "    'nthread': -1,\n",
    "    'num_leaves': 100,\n",
    "    'objective': 'regression_l1',\n",
    "    'seed ': 0,\n",
    "    'silent': False,\n",
    "    'subsample': 1\n",
    "}\n",
    "\n",
    "model = lgb.sklearn.LGBMRegressor(**sk_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe181677470>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApEAAAHwCAYAAAD+azSpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJQkSVK1D05o3wDK2BH+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe181657320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.figure(figsize=(8, 8)).gca()\n",
    "lgb.plotting.plot_importance(model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757, total=  30.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   31.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757, total=  29.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757, total=  29.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757, total=  29.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.954881350393, learning_rate=0.163037873274, max_bin=500, n_estimators=451, nthread=-1, num_leaves=157, objective=regression_l1, seed =0, silent=False, subsample=0.969450347757, total=  28.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463, total=  14.7s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463, total=  15.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463, total=  14.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463, total=  14.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.962356369679, learning_rate=0.0968763414585, max_bin=500, n_estimators=287, nthread=-1, num_leaves=160, objective=regression_l1, seed =0, silent=False, subsample=0.811342595463, total=  14.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475, total=  12.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475, total=  12.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475, total=  12.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475, total=  12.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.927265629458, learning_rate=0.115533023464, max_bin=500, n_estimators=239, nthread=-1, num_leaves=177, objective=regression_l1, seed =0, silent=False, subsample=0.895995434475, total=  15.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441, total=  13.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441, total=  10.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441, total=  10.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441, total=  10.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=dart, colsample_bytree=0.93927847961, learning_rate=0.187215752707, max_bin=500, n_estimators=272, nthread=-1, num_leaves=99, objective=regression_l1, seed =0, silent=False, subsample=0.92963437441, total=  10.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396, total=  23.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396, total=  22.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396, total=  21.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396, total=  17.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.936824153984, learning_rate=0.211431031791, max_bin=500, n_estimators=299, nthread=-1, num_leaves=178, objective=regression_l1, seed =0, silent=False, subsample=0.960182150396, total=  17.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482, total=  39.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482, total=  43.7s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482, total=  31.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482, total=  37.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.952047747955, learning_rate=0.155775906024, max_bin=500, n_estimators=488, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.828670657482, total=  41.1s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421, total=  22.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421, total=  22.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421, total=  26.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421, total=  27.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994466891705, learning_rate=0.12436966435, max_bin=500, n_estimators=444, nthread=-1, num_leaves=113, objective=regression_l1, seed =0, silent=False, subsample=0.852911122421, total=  27.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087, total=  22.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087, total=  25.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087, total=  28.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087, total=  28.1s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.977423368943, learning_rate=0.111230066443, max_bin=500, n_estimators=490, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.803757960087, total=  21.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703, total=  22.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703, total=  27.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703, total=  26.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703, total=  27.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.961763549708, learning_rate=0.142419144544, max_bin=500, n_estimators=444, nthread=-1, num_leaves=107, objective=regression_l1, seed =0, silent=False, subsample=0.988749615703, total=  20.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072, total=  31.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072, total=  36.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072, total=  27.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072, total=  34.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.96818202991, learning_rate=0.0919015801148, max_bin=500, n_estimators=457, nthread=-1, num_leaves=155, objective=regression_l1, seed =0, silent=False, subsample=0.819856070072, total=  34.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394, total=  29.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394, total=  36.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394, total=  27.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394, total=  34.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.996980906775, learning_rate=0.15062800716, max_bin=500, n_estimators=467, nthread=-1, num_leaves=136, objective=regression_l1, seed =0, silent=False, subsample=0.871630433394, total=  35.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692, total=  16.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692, total=  15.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692, total=  17.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692, total=  20.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.975068614122, learning_rate=0.141566133743, max_bin=500, n_estimators=321, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.887720302692, total=  20.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536, total=  18.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536, total=  14.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536, total=  14.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536, total=  16.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.998837383806, learning_rate=0.0404089621496, max_bin=500, n_estimators=327, nthread=-1, num_leaves=93, objective=regression_l1, seed =0, silent=False, subsample=0.999059913536, total=  17.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226, total=  29.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226, total=  27.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226, total=  31.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226, total=  35.6s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.958185032944, learning_rate=0.102873717645, max_bin=500, n_estimators=348, nthread=-1, num_leaves=189, objective=regression_l1, seed =0, silent=False, subsample=0.924702020226, total=  34.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405, total=  14.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405, total=  13.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405, total=  15.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405, total=  17.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.933800761484, learning_rate=0.154950464452, max_bin=500, n_estimators=248, nthread=-1, num_leaves=139, objective=regression_l1, seed =0, silent=False, subsample=0.955669096405, total=  17.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109, total=  19.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109, total=  19.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109, total=  14.4s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109, total=  14.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.994957105345, learning_rate=0.15250537339, max_bin=500, n_estimators=294, nthread=-1, num_leaves=90, objective=regression_l1, seed =0, silent=False, subsample=0.924569219109, total=  16.7s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638, total=  18.7s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638, total=  15.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638, total=  14.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638, total=  16.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.967365963084, learning_rate=0.2143890005, max_bin=500, n_estimators=298, nthread=-1, num_leaves=132, objective=regression_l1, seed =0, silent=False, subsample=0.995352217638, total=  17.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515, total=   9.1s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515, total=   9.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515, total=   8.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515, total=   8.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.960484551975, learning_rate=0.16785271588, max_bin=500, n_estimators=200, nthread=-1, num_leaves=100, objective=regression_l1, seed =0, silent=False, subsample=0.856561392515, total=   7.2s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851, total=  19.8s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851, total=  19.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851, total=  23.5s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851, total=  25.3s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.912019656121, learning_rate=0.0792280395044, max_bin=500, n_estimators=330, nthread=-1, num_leaves=188, objective=regression_l1, seed =0, silent=False, subsample=0.976095177851, total=  19.9s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188, total=  22.7s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188, total=  27.1s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188, total=  26.0s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188, total=  20.7s\n",
      "[CV] boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188 \n",
      "[CV]  boosting_type=dart, colsample_bytree=0.991823546636, learning_rate=0.0633644275255, max_bin=500, n_estimators=427, nthread=-1, num_leaves=110, objective=regression_l1, seed =0, silent=False, subsample=0.853077898188, total=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 37.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.052283366003951816"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'colsample_bytree': 0.99883738380592269,\n",
       " 'learning_rate': 0.040408962149605612,\n",
       " 'max_bin': 500,\n",
       " 'n_estimators': 327,\n",
       " 'nthread': -1,\n",
       " 'num_leaves': 93,\n",
       " 'objective': 'regression_l1',\n",
       " 'seed ': 0,\n",
       " 'silent': False,\n",
       " 'subsample': 0.99905991353557755}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_uniform, randint as sp_randint\n",
    "\n",
    "param_space = {\n",
    "    'boosting_type': ['dart'],\n",
    "    'num_leaves': sp_randint(90, 200),\n",
    "    'learning_rate': sp_uniform(0.02, 0.2),\n",
    "    'n_estimators': sp_randint(200, 500),\n",
    "    'objective': ['regression_l1'],\n",
    "    'subsample': sp_uniform(0.8, 0.2),\n",
    "    'colsample_bytree': sp_uniform(0.9, 0.1),\n",
    "    'nthread': [-1],\n",
    "    'silent': [False],\n",
    "    'seed ' : [0],\n",
    "    'max_bin': [500],\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "rs = RandomizedSearchCV(lgb.sklearn.LGBMRegressor(), param_space, n_jobs=1,\n",
    "                        verbose=2, random_state=0, scoring='neg_mean_absolute_error',\n",
    "                        n_iter=20, cv=5)\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "display(rs.best_score_)\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'l1-mean': [0.052975616553517901,\n",
       "  0.052929230066178265,\n",
       "  0.052886414361944654,\n",
       "  0.052847712966655136,\n",
       "  0.052811588498070036,\n",
       "  0.052779016628197492,\n",
       "  0.052748664667659408,\n",
       "  0.052762446727394371,\n",
       "  0.052735254198982826,\n",
       "  0.052708410717770326,\n",
       "  0.052683003011044408,\n",
       "  0.05269179475456516,\n",
       "  0.052669056539825655,\n",
       "  0.052645528849764256,\n",
       "  0.052624542410007621,\n",
       "  0.052606416011964585,\n",
       "  0.052585072492229587,\n",
       "  0.052565417622733146,\n",
       "  0.052547977834199053,\n",
       "  0.052530268868819383,\n",
       "  0.052534922249834914,\n",
       "  0.052520108762913263,\n",
       "  0.052505504534883465,\n",
       "  0.052491127803250992,\n",
       "  0.052473530819135042,\n",
       "  0.052464365032169037,\n",
       "  0.052450962921254195,\n",
       "  0.052457371860633165,\n",
       "  0.052446109065813519,\n",
       "  0.05243759693860954,\n",
       "  0.052439022795073495,\n",
       "  0.052428702663559278,\n",
       "  0.052417096540569384,\n",
       "  0.052403960168010688,\n",
       "  0.05240767310994239,\n",
       "  0.05241601691719109,\n",
       "  0.052407095409448545,\n",
       "  0.052397530888805458,\n",
       "  0.052388302644882388,\n",
       "  0.052392182862038984,\n",
       "  0.052398767790139487,\n",
       "  0.052386852411181753,\n",
       "  0.05239157918738744,\n",
       "  0.052379646454792303,\n",
       "  0.052369759826528875,\n",
       "  0.052349939796550768,\n",
       "  0.052343990732594714,\n",
       "  0.052342984729256914,\n",
       "  0.052344613969067463,\n",
       "  0.052349281647983262,\n",
       "  0.052340647301545785,\n",
       "  0.052336427569133218,\n",
       "  0.052339451347295798,\n",
       "  0.0523307743485706,\n",
       "  0.052322924828228493,\n",
       "  0.052326762609473929,\n",
       "  0.052320551892463929,\n",
       "  0.052318692496340392,\n",
       "  0.052321744784445588,\n",
       "  0.052317187118116712,\n",
       "  0.052332647570122307,\n",
       "  0.05232386090118122,\n",
       "  0.05231767000743992,\n",
       "  0.052318941516884945,\n",
       "  0.052321148802883341,\n",
       "  0.052314113017355626,\n",
       "  0.052308217499861219,\n",
       "  0.052301654609474044,\n",
       "  0.052303304479380239,\n",
       "  0.05230439520270589,\n",
       "  0.052304482046443099,\n",
       "  0.052297490359893471,\n",
       "  0.052292358736234446,\n",
       "  0.052294408611695299,\n",
       "  0.05228583497774416,\n",
       "  0.052285854897863845,\n",
       "  0.052287867474718419,\n",
       "  0.052290056794682668,\n",
       "  0.052282932183400757,\n",
       "  0.052278824587722636,\n",
       "  0.052280450405498002,\n",
       "  0.052274818199071579,\n",
       "  0.052277972742017786,\n",
       "  0.052280827345320101,\n",
       "  0.052282962576932081,\n",
       "  0.05227594870085199,\n",
       "  0.052270421767943234,\n",
       "  0.052272933905647842,\n",
       "  0.052274894976095908,\n",
       "  0.052276685219319698,\n",
       "  0.052287367666428698,\n",
       "  0.052282433736055844,\n",
       "  0.052277194161810647,\n",
       "  0.052279392760335039,\n",
       "  0.052282656297915973,\n",
       "  0.052284541070635036,\n",
       "  0.052279544066366181,\n",
       "  0.052281940450552622,\n",
       "  0.052278970697950823,\n",
       "  0.052273536465880746,\n",
       "  0.052282201198165922,\n",
       "  0.052283524579087949,\n",
       "  0.05228601380388518,\n",
       "  0.052280055931412453,\n",
       "  0.052288742798948573,\n",
       "  0.052290033757113788,\n",
       "  0.052290707106228643,\n",
       "  0.052285975098108638,\n",
       "  0.052287005124815412,\n",
       "  0.052287624150933541,\n",
       "  0.052281632307995096,\n",
       "  0.052277652233583438,\n",
       "  0.052275386180184139,\n",
       "  0.052269938036111727,\n",
       "  0.052266021473268587,\n",
       "  0.052262424428864272,\n",
       "  0.052263452158905821,\n",
       "  0.052258838370148664,\n",
       "  0.052260339289923144,\n",
       "  0.052261289204541261,\n",
       "  0.052262948135137044,\n",
       "  0.05226433628978331,\n",
       "  0.052259377880619115,\n",
       "  0.052252688896310164,\n",
       "  0.05225415335381297,\n",
       "  0.052255422248720762,\n",
       "  0.052250441969567983,\n",
       "  0.05225210162438363,\n",
       "  0.05224783509564522,\n",
       "  0.052243561819775818,\n",
       "  0.052244864378430469,\n",
       "  0.052241674874736854,\n",
       "  0.052238815556003335,\n",
       "  0.052243519579761165,\n",
       "  0.052238751029484068,\n",
       "  0.052246386141635001,\n",
       "  0.052247723066042071,\n",
       "  0.052242836292043196,\n",
       "  0.052237775455519185,\n",
       "  0.052238654259108265,\n",
       "  0.05223966960009787,\n",
       "  0.052240725122032039,\n",
       "  0.052235846776101283,\n",
       "  0.052236722644858055,\n",
       "  0.052234065892165747,\n",
       "  0.052234608268632174,\n",
       "  0.052235170421220764,\n",
       "  0.052235935074305753,\n",
       "  0.052231023945119318,\n",
       "  0.052227152073102148,\n",
       "  0.052231170445050525,\n",
       "  0.052235793911208306,\n",
       "  0.052232525566394648,\n",
       "  0.052233688919362864,\n",
       "  0.052228405069543557,\n",
       "  0.05222938981660994,\n",
       "  0.052229488720517955,\n",
       "  0.052230223440441148,\n",
       "  0.052231489575418899,\n",
       "  0.052232579330276085,\n",
       "  0.052228597846119919,\n",
       "  0.05222946699676477,\n",
       "  0.052223337075302897,\n",
       "  0.052221293101276302,\n",
       "  0.052218818776346446,\n",
       "  0.052215141158236444,\n",
       "  0.052211356774499194,\n",
       "  0.052209178770537587,\n",
       "  0.052202639507393879,\n",
       "  0.052206014211829702,\n",
       "  0.05220391884036104,\n",
       "  0.052207346701692782,\n",
       "  0.052204459090252044,\n",
       "  0.052203064753253758,\n",
       "  0.052200617880110753,\n",
       "  0.05220130134736841,\n",
       "  0.05220208232690475,\n",
       "  0.052202335177151019,\n",
       "  0.052199359019115835,\n",
       "  0.052200023442758779,\n",
       "  0.052199241065074765,\n",
       "  0.052194921376111349,\n",
       "  0.052192825085961514,\n",
       "  0.052190112582893723,\n",
       "  0.052191180118003035,\n",
       "  0.052188336090161616,\n",
       "  0.052183677606286706,\n",
       "  0.052182211296479597,\n",
       "  0.052182812671678389,\n",
       "  0.052183502092809406,\n",
       "  0.052181354825731184,\n",
       "  0.052179079404892401,\n",
       "  0.052177395842387134,\n",
       "  0.05217778113724416,\n",
       "  0.052178445519101016,\n",
       "  0.052177283053946352,\n",
       "  0.052177901923163995,\n",
       "  0.052178533091159482,\n",
       "  0.052176254031475043,\n",
       "  0.052176981403277735,\n",
       "  0.052177927618474992,\n",
       "  0.052178677004922971,\n",
       "  0.052175367933641206,\n",
       "  0.052176101993059512,\n",
       "  0.052178412921895082,\n",
       "  0.052177097649543799,\n",
       "  0.052177829111915854,\n",
       "  0.052176711477952574,\n",
       "  0.052177293705142201,\n",
       "  0.052177885029113101,\n",
       "  0.052178359478986844,\n",
       "  0.052179377086701541,\n",
       "  0.052176140016706084,\n",
       "  0.052174917326523074,\n",
       "  0.052173433360518162,\n",
       "  0.052173912812627919,\n",
       "  0.052171090895785845,\n",
       "  0.052169516070289371,\n",
       "  0.052171588447407567,\n",
       "  0.052169326279409109,\n",
       "  0.05216978580512581,\n",
       "  0.052168621129737559,\n",
       "  0.052168422536117795,\n",
       "  0.052169146307383361,\n",
       "  0.052169639996464554,\n",
       "  0.052170269619586394,\n",
       "  0.052170559889009704,\n",
       "  0.052168111244843531,\n",
       "  0.052168622055490811,\n",
       "  0.052167216235941116,\n",
       "  0.05216406800125041,\n",
       "  0.052162624433545191,\n",
       "  0.052163218065798524,\n",
       "  0.052162647802395733,\n",
       "  0.052163093294412391,\n",
       "  0.052161737688317597,\n",
       "  0.052158828424402823,\n",
       "  0.05215777347247328,\n",
       "  0.052156306601054261,\n",
       "  0.052154745365957968,\n",
       "  0.052155112506834932,\n",
       "  0.052153452842994927,\n",
       "  0.052153748119795042,\n",
       "  0.052154993905987768,\n",
       "  0.052155102668557198,\n",
       "  0.052153767262751963,\n",
       "  0.05215403296483534,\n",
       "  0.052154211917305585,\n",
       "  0.052154554019198399,\n",
       "  0.05215311525753609,\n",
       "  0.052153351259197275,\n",
       "  0.052153523781579905,\n",
       "  0.052151693978140033,\n",
       "  0.05215120534516042,\n",
       "  0.052150321390089883,\n",
       "  0.052149392813524043,\n",
       "  0.052148625620811781,\n",
       "  0.052149117088421862,\n",
       "  0.052149397140128187,\n",
       "  0.052149540099124127,\n",
       "  0.05214987737645168,\n",
       "  0.052147768555165994,\n",
       "  0.052145802517643523,\n",
       "  0.052143752777041405,\n",
       "  0.052141112363120024,\n",
       "  0.052141467226581431,\n",
       "  0.052141946674880736,\n",
       "  0.052140886869790501,\n",
       "  0.052141092824429268,\n",
       "  0.052139925368091443,\n",
       "  0.05214029364718633,\n",
       "  0.052140661630483032,\n",
       "  0.052140491143671731,\n",
       "  0.052140696596803461,\n",
       "  0.052140639749521198,\n",
       "  0.052141120675060923,\n",
       "  0.052139586426596676,\n",
       "  0.052139886679688996,\n",
       "  0.052138336810505934,\n",
       "  0.052138704174236293,\n",
       "  0.05213959021192234,\n",
       "  0.052139718752032063,\n",
       "  0.052140219183518209,\n",
       "  0.052137109472045529,\n",
       "  0.052135927245453198,\n",
       "  0.052134176317144489,\n",
       "  0.052135343472761511,\n",
       "  0.052135694784297935,\n",
       "  0.052136511738012238,\n",
       "  0.052134711259893274,\n",
       "  0.05213300330006064,\n",
       "  0.052133053884238265,\n",
       "  0.052133359628555996,\n",
       "  0.052130970313083426,\n",
       "  0.052131223280102432,\n",
       "  0.052131459633673716,\n",
       "  0.052130117290659819,\n",
       "  0.052130321291282242,\n",
       "  0.052128462838969325,\n",
       "  0.052128756144175337,\n",
       "  0.052129528383081748,\n",
       "  0.052130326482830315,\n",
       "  0.052130644881846357,\n",
       "  0.052130836259179858,\n",
       "  0.052131132264488997,\n",
       "  0.052131429005982055,\n",
       "  0.052131751730148071,\n",
       "  0.052130606769634338,\n",
       "  0.052130696276099987,\n",
       "  0.05212989128817791,\n",
       "  0.05212891701118938,\n",
       "  0.052128840463390447,\n",
       "  0.052128296226603067,\n",
       "  0.052129077428728375,\n",
       "  0.052129142404442032,\n",
       "  0.052128674469310167,\n",
       "  0.05212561911413359,\n",
       "  0.052126197267118049,\n",
       "  0.052126461128663801,\n",
       "  0.052126434195249163,\n",
       "  0.052126706886622021,\n",
       "  0.052124915418017136,\n",
       "  0.052123974273661486,\n",
       "  0.05212431329869438,\n",
       "  0.052125164203517017,\n",
       "  0.052125433333352046,\n",
       "  0.052123489643395492,\n",
       "  0.052123681330206374,\n",
       "  0.052124721918648198,\n",
       "  0.052124976847959713,\n",
       "  0.052125170678165654,\n",
       "  0.052125879793111639,\n",
       "  0.052126187733665744,\n",
       "  0.052126504861741751,\n",
       "  0.05212580301402623,\n",
       "  0.052126027066048686,\n",
       "  0.05212580564993681,\n",
       "  0.05212556944288519,\n",
       "  0.05212573172929149,\n",
       "  0.0521258563012819,\n",
       "  0.05212490187555905,\n",
       "  0.052123831003432895,\n",
       "  0.052123429605717406,\n",
       "  0.052123617353144205,\n",
       "  0.052122720110923462,\n",
       "  0.052119953894941139,\n",
       "  0.052120083421399198,\n",
       "  0.052118398460753723,\n",
       "  0.052118299944414657,\n",
       "  0.052118555307540101,\n",
       "  0.052117086372602595,\n",
       "  0.052116650986350099,\n",
       "  0.052117018762855273,\n",
       "  0.052117157626231717,\n",
       "  0.052117289127212071,\n",
       "  0.05211770254080493,\n",
       "  0.052117764888305662,\n",
       "  0.052117612174601646,\n",
       "  0.052118165468916032,\n",
       "  0.052115743016948046,\n",
       "  0.052115568082520367,\n",
       "  0.052116100794182704,\n",
       "  0.052116150887050808,\n",
       "  0.052116275683957367,\n",
       "  0.052115046323615355,\n",
       "  0.052115180776313663,\n",
       "  0.052115279755267085,\n",
       "  0.052114666548354303,\n",
       "  0.05211484543843279,\n",
       "  0.052114599890780967,\n",
       "  0.052114965821863847,\n",
       "  0.052114647436663608,\n",
       "  0.052114946787193285,\n",
       "  0.052114146158676475,\n",
       "  0.052113579033819822,\n",
       "  0.052113689795040406,\n",
       "  0.052112134357206366,\n",
       "  0.05211220195660602,\n",
       "  0.052112292648615097,\n",
       "  0.052110921117360487,\n",
       "  0.052111082665492824,\n",
       "  0.052111293221898961,\n",
       "  0.052110002812125099,\n",
       "  0.052108772186912643,\n",
       "  0.052108815547632234,\n",
       "  0.052108872248598156,\n",
       "  0.052108431566983929,\n",
       "  0.052107464085629315,\n",
       "  0.052108241246943666,\n",
       "  0.052109788322931859,\n",
       "  0.052109851412472277,\n",
       "  0.052109304862555827,\n",
       "  0.052109979242845474,\n",
       "  0.05211074115777322,\n",
       "  0.052110981135909173,\n",
       "  0.052110967249594409,\n",
       "  0.052108311903987216,\n",
       "  0.052108828834992529,\n",
       "  0.05210801249421286,\n",
       "  0.052108297223758912,\n",
       "  0.052108349938902489,\n",
       "  0.052108291766428595,\n",
       "  0.05210827887891524,\n",
       "  0.052108868118406038,\n",
       "  0.05210735542338385,\n",
       "  0.05210755270813807,\n",
       "  0.052107513224872851,\n",
       "  0.052107602555068945,\n",
       "  0.052107860954847263,\n",
       "  0.052108662767268957,\n",
       "  0.052108245775334697,\n",
       "  0.052108264429466256,\n",
       "  0.052108115463644619,\n",
       "  0.052107913277407325,\n",
       "  0.052107791629653309,\n",
       "  0.052108245846829084,\n",
       "  0.052108193607573149,\n",
       "  0.052108204607115439,\n",
       "  0.052106568106421468,\n",
       "  0.052106667263569231,\n",
       "  0.052105268590202189,\n",
       "  0.052105350682404315,\n",
       "  0.05210418992271898,\n",
       "  0.052104004505220999,\n",
       "  0.052104047247726305,\n",
       "  0.052105198346127,\n",
       "  0.052104766236752934,\n",
       "  0.052104779116267597,\n",
       "  0.05210359250791502,\n",
       "  0.052103843632691868,\n",
       "  0.052103467891221798,\n",
       "  0.052100067520455394,\n",
       "  0.052100305125910504,\n",
       "  0.052100411766306712,\n",
       "  0.052100544826421236,\n",
       "  0.052102086005684133,\n",
       "  0.052102056131727768,\n",
       "  0.052102027691951124,\n",
       "  0.052101983234631499,\n",
       "  0.052101938761474786,\n",
       "  0.052102765632233691,\n",
       "  0.052101154377827461,\n",
       "  0.052100996688945168,\n",
       "  0.052101080402123891,\n",
       "  0.052101048960840023,\n",
       "  0.052100565378741318,\n",
       "  0.052100512278030087,\n",
       "  0.052101408574148189,\n",
       "  0.052101300908737526,\n",
       "  0.052100070334446101,\n",
       "  0.052100033851722238,\n",
       "  0.052100193879550762,\n",
       "  0.05210018997493706,\n",
       "  0.052099751534974606,\n",
       "  0.052098500542773908,\n",
       "  0.052098487956023877,\n",
       "  0.052098403233037958,\n",
       "  0.052098447266404155,\n",
       "  0.052098519208898839,\n",
       "  0.05210091578831709,\n",
       "  0.052100659063850016,\n",
       "  0.052100678368632893,\n",
       "  0.052100561288982015,\n",
       "  0.052100465939189676,\n",
       "  0.052101032608461904,\n",
       "  0.052099895332240499,\n",
       "  0.052098526572460689,\n",
       "  0.052098703656561461,\n",
       "  0.052098610629623267,\n",
       "  0.052098777284456756,\n",
       "  0.052097824361757826,\n",
       "  0.052097902609406624,\n",
       "  0.052097339989973047,\n",
       "  0.052100141749179173,\n",
       "  0.052100278463602614,\n",
       "  0.052100251669156307,\n",
       "  0.052102712851918288,\n",
       "  0.052102683197146359,\n",
       "  0.052103853858014339,\n",
       "  0.052102517655491253,\n",
       "  0.052102621420742547,\n",
       "  0.052102335299930282,\n",
       "  0.052102304358651076,\n",
       "  0.052102187989409944,\n",
       "  0.052101225765077051,\n",
       "  0.052101117714552558,\n",
       "  0.052101047604321618,\n",
       "  0.05210109460568433,\n",
       "  0.052099151952091152,\n",
       "  0.052099209811848936,\n",
       "  0.052098685755810961,\n",
       "  0.05209869512135068,\n",
       "  0.052099989926974913,\n",
       "  0.052100537605756447,\n",
       "  0.052100304206268266,\n",
       "  0.052100235431192743,\n",
       "  0.052100256966666092,\n",
       "  0.052099103194093707,\n",
       "  0.052099121049223096,\n",
       "  0.052099132496395195,\n",
       "  0.05209900904101461,\n",
       "  0.052098800327150231,\n",
       "  0.052098624226260791,\n",
       "  0.052098665670993638,\n",
       "  0.052097283960849075,\n",
       "  0.052096037521177217],\n",
       " 'l1-stdv': [0.0026660507043730838,\n",
       "  0.0026718861983100728,\n",
       "  0.0026762766847847879,\n",
       "  0.0026776432131336565,\n",
       "  0.0026793379101780418,\n",
       "  0.0026806815808947081,\n",
       "  0.0026837208362389111,\n",
       "  0.0026832839891398554,\n",
       "  0.0026862087011390542,\n",
       "  0.0026867375861245042,\n",
       "  0.002687704629120703,\n",
       "  0.0026876672264734241,\n",
       "  0.0026866851433722098,\n",
       "  0.0026870266712518878,\n",
       "  0.0026860600430303537,\n",
       "  0.0026863671294210917,\n",
       "  0.0026837882952108509,\n",
       "  0.0026845600716293217,\n",
       "  0.0026861085815361864,\n",
       "  0.0026876030914000011,\n",
       "  0.0026865188296665505,\n",
       "  0.0026864752581344984,\n",
       "  0.0026892409055319748,\n",
       "  0.0026918911597127817,\n",
       "  0.0026910090488294781,\n",
       "  0.0026923010626276078,\n",
       "  0.0026940073915944704,\n",
       "  0.0026932244454689392,\n",
       "  0.0026906731998741335,\n",
       "  0.0026890665919698715,\n",
       "  0.0026896846193732804,\n",
       "  0.0026909473865557093,\n",
       "  0.0026913731086311509,\n",
       "  0.0026911645593837514,\n",
       "  0.0026919688916980547,\n",
       "  0.0026921593230990952,\n",
       "  0.0026925196457521661,\n",
       "  0.0026917285517038332,\n",
       "  0.0026931002256906983,\n",
       "  0.0026928942169566002,\n",
       "  0.002692588893322486,\n",
       "  0.0026935771255543767,\n",
       "  0.0026945109487895216,\n",
       "  0.0026935905315689196,\n",
       "  0.0026922600452831836,\n",
       "  0.0027034060041127715,\n",
       "  0.0027018425530140533,\n",
       "  0.002702305459076374,\n",
       "  0.0027020022940528474,\n",
       "  0.0027029783608548304,\n",
       "  0.0027034091065324946,\n",
       "  0.0027007047175329479,\n",
       "  0.0027006706813575121,\n",
       "  0.0026981151583093678,\n",
       "  0.0026952513336238426,\n",
       "  0.0026946286724175636,\n",
       "  0.0026925419159584034,\n",
       "  0.0027033498402269656,\n",
       "  0.0027038081071168161,\n",
       "  0.0027017220952162482,\n",
       "  0.0027089902871297688,\n",
       "  0.0027055501682119619,\n",
       "  0.0027039155303326162,\n",
       "  0.0027033244638415767,\n",
       "  0.0027043197216792816,\n",
       "  0.0027000849201154094,\n",
       "  0.0026977464044909269,\n",
       "  0.0026952082948185699,\n",
       "  0.0026950994222931525,\n",
       "  0.0026951306846526146,\n",
       "  0.0026954734100145365,\n",
       "  0.0026943036497832119,\n",
       "  0.002692906729942142,\n",
       "  0.002693617288416337,\n",
       "  0.0026925833229868358,\n",
       "  0.0026915356759155146,\n",
       "  0.002692319878806275,\n",
       "  0.0026930563064492432,\n",
       "  0.0026907140241483442,\n",
       "  0.0026875784537860842,\n",
       "  0.0026880396558985036,\n",
       "  0.0026851742795512643,\n",
       "  0.0026860066900435691,\n",
       "  0.0026866498310172851,\n",
       "  0.0026873453416523868,\n",
       "  0.0026861720233634524,\n",
       "  0.0026839003447928183,\n",
       "  0.0026841811906653077,\n",
       "  0.0026843310957187453,\n",
       "  0.0026844067696245484,\n",
       "  0.002691542446396575,\n",
       "  0.0026917663820897881,\n",
       "  0.0026923328876370797,\n",
       "  0.0026928224410584125,\n",
       "  0.002693509423569771,\n",
       "  0.0026936883705088793,\n",
       "  0.0026911527707799013,\n",
       "  0.0026912500625858736,\n",
       "  0.0026911246377619986,\n",
       "  0.0026899665292963756,\n",
       "  0.0026930758861769123,\n",
       "  0.0026928954945851795,\n",
       "  0.0026936007158777117,\n",
       "  0.0026919933101295897,\n",
       "  0.0026946309303551748,\n",
       "  0.0026945904234092909,\n",
       "  0.0026946962573820049,\n",
       "  0.0026924262929889147,\n",
       "  0.0026926435755443468,\n",
       "  0.0026928299929662924,\n",
       "  0.0026915630122934259,\n",
       "  0.0026917998632027527,\n",
       "  0.0026915208635418602,\n",
       "  0.0026891063997934359,\n",
       "  0.0026881198305885889,\n",
       "  0.0026872374891562714,\n",
       "  0.0026874624089444966,\n",
       "  0.0026855731925222097,\n",
       "  0.0026859185666305969,\n",
       "  0.0026859268772078718,\n",
       "  0.0026865866113107745,\n",
       "  0.0026868562733008239,\n",
       "  0.0026858183256261397,\n",
       "  0.0026852318986079443,\n",
       "  0.0026857265183193703,\n",
       "  0.0026859097683633055,\n",
       "  0.0026851076143885513,\n",
       "  0.0026855272367571174,\n",
       "  0.0026843666439924441,\n",
       "  0.0026830749171174954,\n",
       "  0.002683163124986716,\n",
       "  0.0026817229579219662,\n",
       "  0.0026798286864352281,\n",
       "  0.0026823641352390951,\n",
       "  0.0026789878835125664,\n",
       "  0.0026817012535965113,\n",
       "  0.0026819514023297573,\n",
       "  0.0026807692473588625,\n",
       "  0.0026793722623420901,\n",
       "  0.0026796191029451518,\n",
       "  0.002679828808312512,\n",
       "  0.0026805338851319856,\n",
       "  0.0026794108537004611,\n",
       "  0.0026797155152400386,\n",
       "  0.0026782638349804036,\n",
       "  0.0026786769855926085,\n",
       "  0.0026792657558264502,\n",
       "  0.0026796099652268523,\n",
       "  0.0026790898443762754,\n",
       "  0.002678803572880346,\n",
       "  0.002680190271660499,\n",
       "  0.0026818754611509375,\n",
       "  0.0026820010234749041,\n",
       "  0.0026823676122562337,\n",
       "  0.0026794547401681568,\n",
       "  0.0026796772986427703,\n",
       "  0.0026798431733214075,\n",
       "  0.0026800833026937605,\n",
       "  0.0026805649110224618,\n",
       "  0.0026809707597812401,\n",
       "  0.0026782136880796194,\n",
       "  0.0026783302632835591,\n",
       "  0.0026769787151161781,\n",
       "  0.0026754406196732743,\n",
       "  0.0026762153821692902,\n",
       "  0.0026765884200156643,\n",
       "  0.0026765346384741147,\n",
       "  0.0026772502923694966,\n",
       "  0.002677874165691695,\n",
       "  0.0026792857590865935,\n",
       "  0.0026778987459684721,\n",
       "  0.0026793497080880675,\n",
       "  0.0026771505970637622,\n",
       "  0.002676875660834346,\n",
       "  0.0026783216481346839,\n",
       "  0.0026791018700178192,\n",
       "  0.0026793012221302749,\n",
       "  0.002679429932113184,\n",
       "  0.0026799645588444967,\n",
       "  0.0026803987129645334,\n",
       "  0.0026812896633155634,\n",
       "  0.0026808782498194228,\n",
       "  0.0026768574226310243,\n",
       "  0.0026780033111662212,\n",
       "  0.0026780418668480317,\n",
       "  0.0026780265352145706,\n",
       "  0.0026795082386293508,\n",
       "  0.0026783859121726418,\n",
       "  0.0026785727825313415,\n",
       "  0.0026791156518303303,\n",
       "  0.0026801919783348326,\n",
       "  0.0026804122337798103,\n",
       "  0.0026811961133172231,\n",
       "  0.0026814620501052142,\n",
       "  0.0026817361128285999,\n",
       "  0.0026807739303489897,\n",
       "  0.0026813692752048271,\n",
       "  0.0026819594332057233,\n",
       "  0.0026806370265550811,\n",
       "  0.0026812381960465543,\n",
       "  0.0026817961263429146,\n",
       "  0.0026822542683414266,\n",
       "  0.0026816795439373211,\n",
       "  0.0026820889174747143,\n",
       "  0.002683622923967064,\n",
       "  0.0026834407547110624,\n",
       "  0.0026836607094611132,\n",
       "  0.0026831499862001291,\n",
       "  0.0026833830196528134,\n",
       "  0.0026835945087206022,\n",
       "  0.002684066049536448,\n",
       "  0.0026856634931729808,\n",
       "  0.00268601770803164,\n",
       "  0.0026856634821028698,\n",
       "  0.0026868551795155363,\n",
       "  0.0026868948857057804,\n",
       "  0.002687455541881858,\n",
       "  0.0026889536096859202,\n",
       "  0.0026900910251974244,\n",
       "  0.0026898496387751849,\n",
       "  0.0026900407087950755,\n",
       "  0.0026877925665820582,\n",
       "  0.0026875647728330796,\n",
       "  0.00268764396802484,\n",
       "  0.002687765274027983,\n",
       "  0.002687955923977105,\n",
       "  0.0026885237482282736,\n",
       "  0.0026871770977050964,\n",
       "  0.0026873568068607511,\n",
       "  0.0026852508392877462,\n",
       "  0.0026846565791640345,\n",
       "  0.0026847253403511615,\n",
       "  0.0026851165953311424,\n",
       "  0.0026855174574919503,\n",
       "  0.002685728391653095,\n",
       "  0.0026842682014433464,\n",
       "  0.0026848747244059864,\n",
       "  0.0026823425578261259,\n",
       "  0.0026822390069453964,\n",
       "  0.0026824941916641543,\n",
       "  0.0026829771600600993,\n",
       "  0.002682781510535187,\n",
       "  0.0026832805725447895,\n",
       "  0.002684482728032951,\n",
       "  0.0026833840495946344,\n",
       "  0.002684216122539225,\n",
       "  0.0026831721765279005,\n",
       "  0.0026833995752244253,\n",
       "  0.0026836219234874295,\n",
       "  0.0026842687647307705,\n",
       "  0.0026844819250541841,\n",
       "  0.0026849686470569148,\n",
       "  0.002684332045645495,\n",
       "  0.0026847102056759414,\n",
       "  0.0026849634212736642,\n",
       "  0.0026844126418262308,\n",
       "  0.0026831030208324569,\n",
       "  0.0026843395915802835,\n",
       "  0.002684475583588444,\n",
       "  0.0026850306945555343,\n",
       "  0.0026853330033123558,\n",
       "  0.0026839217598780812,\n",
       "  0.0026842959328396009,\n",
       "  0.0026850777899700149,\n",
       "  0.0026843557954796897,\n",
       "  0.0026852659420766186,\n",
       "  0.0026855246868704983,\n",
       "  0.0026835687855095232,\n",
       "  0.0026837384542678336,\n",
       "  0.0026837840345040062,\n",
       "  0.0026838377385935319,\n",
       "  0.0026848477490720207,\n",
       "  0.0026831167941138889,\n",
       "  0.0026835570045619407,\n",
       "  0.0026850054268531677,\n",
       "  0.0026851760074882336,\n",
       "  0.0026848127329828627,\n",
       "  0.0026852343123478844,\n",
       "  0.0026837954910406323,\n",
       "  0.002683859538363842,\n",
       "  0.0026846324919618655,\n",
       "  0.0026849625232398095,\n",
       "  0.0026853099024243682,\n",
       "  0.0026841553421234001,\n",
       "  0.0026838563966423098,\n",
       "  0.0026822809232095908,\n",
       "  0.0026824929833136175,\n",
       "  0.002682667697927083,\n",
       "  0.0026834643848025722,\n",
       "  0.0026813609315202176,\n",
       "  0.0026810759232428439,\n",
       "  0.002680997101561848,\n",
       "  0.0026813323773017786,\n",
       "  0.0026818587158708002,\n",
       "  0.0026820025190719939,\n",
       "  0.0026823670867404349,\n",
       "  0.0026812670190288004,\n",
       "  0.0026815184562737691,\n",
       "  0.0026835648648801187,\n",
       "  0.0026836220937624176,\n",
       "  0.0026843372640519038,\n",
       "  0.002683092784862747,\n",
       "  0.0026833166601315192,\n",
       "  0.0026834192880268604,\n",
       "  0.0026836017544730208,\n",
       "  0.0026836053446903205,\n",
       "  0.0026837221261403273,\n",
       "  0.0026826088213722904,\n",
       "  0.0026826727269199722,\n",
       "  0.0026824568608636089,\n",
       "  0.0026807482911313969,\n",
       "  0.0026823784777703173,\n",
       "  0.0026831469035838505,\n",
       "  0.0026838836012583506,\n",
       "  0.0026840657381465389,\n",
       "  0.0026837231472408274,\n",
       "  0.0026844509584479023,\n",
       "  0.0026846408718859275,\n",
       "  0.0026848660182609645,\n",
       "  0.0026859427078334405,\n",
       "  0.0026863230358154977,\n",
       "  0.002686124322020601,\n",
       "  0.0026858555047680715,\n",
       "  0.002685880954808192,\n",
       "  0.0026851691785212259,\n",
       "  0.0026854272358858657,\n",
       "  0.0026853900564726241,\n",
       "  0.002685568810919406,\n",
       "  0.0026851775571500036,\n",
       "  0.0026856321524327872,\n",
       "  0.0026859545959694131,\n",
       "  0.0026865250766454248,\n",
       "  0.0026866707508588733,\n",
       "  0.0026868681760651592,\n",
       "  0.0026871339783110957,\n",
       "  0.0026873924304568705,\n",
       "  0.0026861515415796343,\n",
       "  0.0026849005705699741,\n",
       "  0.0026851180905250265,\n",
       "  0.0026853690637260023,\n",
       "  0.0026864499019028363,\n",
       "  0.0026867523144074477,\n",
       "  0.0026859023575607848,\n",
       "  0.0026861642356754093,\n",
       "  0.0026855333091845399,\n",
       "  0.0026836840011719601,\n",
       "  0.0026838147138807133,\n",
       "  0.002684256629724806,\n",
       "  0.002684307142628376,\n",
       "  0.0026845010341249643,\n",
       "  0.0026821780985584313,\n",
       "  0.002682227121556368,\n",
       "  0.0026834645763526015,\n",
       "  0.0026836268731039365,\n",
       "  0.0026838033398332434,\n",
       "  0.0026843035768010469,\n",
       "  0.0026844936469988161,\n",
       "  0.0026834528533452883,\n",
       "  0.0026840832458505386,\n",
       "  0.0026855740669784562,\n",
       "  0.0026837762584511525,\n",
       "  0.0026827532129846589,\n",
       "  0.0026828827224115066,\n",
       "  0.0026829863385222073,\n",
       "  0.00268269138763606,\n",
       "  0.0026827803923784176,\n",
       "  0.0026828500412280692,\n",
       "  0.002682283241555249,\n",
       "  0.0026824298511231998,\n",
       "  0.0026837931227153612,\n",
       "  0.0026838816772574345,\n",
       "  0.0026854074565445833,\n",
       "  0.0026858888064715002,\n",
       "  0.0026876396144057883,\n",
       "  0.002685795700538065,\n",
       "  0.0026859187112237468,\n",
       "  0.0026872305402726514,\n",
       "  0.0026873215603903885,\n",
       "  0.0026873637820171914,\n",
       "  0.002686205241917749,\n",
       "  0.0026862501584997986,\n",
       "  0.0026863420266129701,\n",
       "  0.0026881160297496185,\n",
       "  0.0026888312213120204,\n",
       "  0.0026888892662810505,\n",
       "  0.0026890794071106994,\n",
       "  0.0026902091612898619,\n",
       "  0.0026885510794754375,\n",
       "  0.0026882948646755498,\n",
       "  0.0026877208212330774,\n",
       "  0.002687797011864306,\n",
       "  0.0026867863480467156,\n",
       "  0.002688052657199996,\n",
       "  0.0026874116787566418,\n",
       "  0.0026880650616449859,\n",
       "  0.0026882349178003187,\n",
       "  0.0026873709749834439,\n",
       "  0.0026877603764397149,\n",
       "  0.0026885036793125859,\n",
       "  0.0026876103078105657,\n",
       "  0.0026876281316071463,\n",
       "  0.0026861212515906902,\n",
       "  0.0026861891068682762,\n",
       "  0.0026857258902772238,\n",
       "  0.0026854110725169624,\n",
       "  0.0026859781060988128,\n",
       "  0.0026841878279751977,\n",
       "  0.0026841260497462963,\n",
       "  0.0026812056770097762,\n",
       "  0.0026792234630097717,\n",
       "  0.0026781833692239815,\n",
       "  0.0026784255724701393,\n",
       "  0.0026785858462163256,\n",
       "  0.0026766552027583132,\n",
       "  0.0026778019335745745,\n",
       "  0.0026773471128807721,\n",
       "  0.0026776486540987057,\n",
       "  0.0026777718303843713,\n",
       "  0.002677165327250727,\n",
       "  0.0026775095727189905,\n",
       "  0.0026773012364049872,\n",
       "  0.002676416127877146,\n",
       "  0.0026763764072270787,\n",
       "  0.0026757469664767425,\n",
       "  0.0026759989241478552,\n",
       "  0.0026751683371796621,\n",
       "  0.0026752183118544217,\n",
       "  0.0026755636083742392,\n",
       "  0.0026744500385784908,\n",
       "  0.0026748539396929728,\n",
       "  0.0026746893583129926,\n",
       "  0.0026743079242062045,\n",
       "  0.002674444453923223,\n",
       "  0.0026745424382510355,\n",
       "  0.002674713284974099,\n",
       "  0.0026744112329696824,\n",
       "  0.0026728598538706965,\n",
       "  0.0026728798640799582,\n",
       "  0.0026734510402711725,\n",
       "  0.0026735138407755522,\n",
       "  0.0026716364776247807,\n",
       "  0.0026709118503596314,\n",
       "  0.0026712495509463234,\n",
       "  0.0026714793989605344,\n",
       "  0.0026716651693336983,\n",
       "  0.0026715563966193553,\n",
       "  0.0026716032957793223,\n",
       "  0.0026718555258033192,\n",
       "  0.0026720606592726898,\n",
       "  0.0026736378025672318,\n",
       "  0.0026738074618899285,\n",
       "  0.0026738976843535523,\n",
       "  0.0026740942572513371,\n",
       "  0.0026745306904232789,\n",
       "  0.002675076361752919,\n",
       "  0.0026752002222480914,\n",
       "  0.0026754536947936136,\n",
       "  0.00267555796411549,\n",
       "  0.002675662506006731,\n",
       "  0.0026749750338643519,\n",
       "  0.0026753170829744741,\n",
       "  0.0026754598756388993,\n",
       "  0.002675785216448769,\n",
       "  0.0026748064257331693,\n",
       "  0.0026741227994428493,\n",
       "  0.0026732028043963451,\n",
       "  0.0026731096054036338,\n",
       "  0.0026735528402175575,\n",
       "  0.0026736499134953021,\n",
       "  0.0026737120086221733,\n",
       "  0.0026765684901964805,\n",
       "  0.0026766508308496777,\n",
       "  0.0026773199514287162,\n",
       "  0.002677276398522244,\n",
       "  0.0026776375215861194,\n",
       "  0.0026778043725747152,\n",
       "  0.002676924744177626,\n",
       "  0.0026764854932976472,\n",
       "  0.0026768995057473021,\n",
       "  0.0026762532534705926,\n",
       "  0.002676436695987057,\n",
       "  0.0026767406621025264,\n",
       "  0.0026767997553638029,\n",
       "  0.0026769555758295134,\n",
       "  0.0026761441143721308,\n",
       "  0.0026763510751841601,\n",
       "  0.0026765701910693414,\n",
       "  0.0026771312044159643,\n",
       "  0.0026775481414648876,\n",
       "  0.0026777415495765938,\n",
       "  0.0026777815370096557,\n",
       "  0.00267781108675495,\n",
       "  0.0026779970224167526,\n",
       "  0.0026777105113476203,\n",
       "  0.0026768217049052143,\n",
       "  0.0026770113032402801,\n",
       "  0.002677268272185551,\n",
       "  0.0026759139884990468,\n",
       "  0.0026759888715898162,\n",
       "  0.0026761039892251835,\n",
       "  0.0026764289318530949,\n",
       "  0.0026766275278625523,\n",
       "  0.0026768159881609454,\n",
       "  0.0026769380176728166,\n",
       "  0.0026763128598545475,\n",
       "  0.0026766575694917361]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain2 = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'dart',\n",
    "    'colsample_bytree': 0.99883738380592269,\n",
    "    'learning_rate': 0.040408962149605612,\n",
    "    'max_bin': 500,\n",
    "#     'n_estimators': 327,\n",
    "    'nthread': -1,\n",
    "    'num_leaves': 93,\n",
    "    'objective': 'regression_l1',\n",
    "    'seed ': 0,\n",
    "#     'silent': False,\n",
    "    'subsample': 0.99905991353557755\n",
    "}\n",
    "\n",
    "hist = lgb.cv(params=params, train_set=dtrain2, metrics='mae', num_boost_round=1000, early_stopping_rounds=100)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.052264357768842695, 0.0010737548403856121)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_params = {\n",
    "    'boosting_type': 'dart',\n",
    "    'colsample_bytree': 0.99883738380592269,\n",
    "    'learning_rate': 0.040408962149605612,\n",
    "    'max_bin': 500,\n",
    "    'n_estimators': 327,\n",
    "    'nthread': -1,\n",
    "    'num_leaves': 93,\n",
    "    'objective': 'regression_l1',\n",
    "    'seed ': 0,\n",
    "    'silent': False,\n",
    "    'subsample': 0.99905991353557755\n",
    "}\n",
    "\n",
    "cv_score = cross_val_score(lgb.sklearn.LGBMRegressor(**sk_params), X_train, y_train,\n",
    "                           cv=10, scoring='neg_mean_absolute_error', verbose=1)\n",
    "cv_score.mean(), cv_score.std()*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058646630702640264"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, rs.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId  201610  201611  201612  201710  201711  201712\n",
       "0  10754147       0       0       0       0       0       0\n",
       "1  10759547       0       0       0       0       0       0\n",
       "2  10843547       0       0       0       0       0       0\n",
       "3  10859147       0       0       0       0       0       0\n",
       "4  10879947       0       0       0       0       0       0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df = pd.read_csv('./data/sample_submission.csv')\n",
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', colsample_bytree=0.9988373838059227,\n",
       "       learning_rate=0.04040896214960561, max_bin=500, max_depth=-1,\n",
       "       min_child_samples=10, min_child_weight=5, min_split_gain=0,\n",
       "       n_estimators=327, nthread=-1, num_leaves=93,\n",
       "       objective='regression_l1', reg_alpha=0, reg_lambda=0, seed=0,\n",
       "       seed =0, silent=False, subsample=0.9990599135355775,\n",
       "       subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, *_, month_agg = preprocess(df_train, rejected_cols1 + rejected_cols2)\n",
    "\n",
    "model = lgb.sklearn.LGBMRegressor(**sk_params)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff997fcc39604500b1b480fa1026984e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-1a16e95049e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdmn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubm_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mm_nr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mm_lerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonth_agg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogerror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     xx, *_ = preprocess(test_df, rejected_cols1+rejected_cols2,\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdmn\n",
    "\n",
    "test_df = props_df.loc[props_df.parcelid.isin(subm_df.ParcelId)]\n",
    "\n",
    "for m in tqdmn(subm_df.columns[1:]):\n",
    "    m_nr = int(m[-2:])\n",
    "    m_lerr = month_agg.loc[m_nr].logerror\n",
    "    xx, *_ = preprocess(test_df, rejected_cols1+rejected_cols2,\n",
    "                        month_agg=(m_nr, m_lerr))\n",
    "    gc.collect()\n",
    "    subm_df[m] = model.predict(xx)\n",
    "subm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.040290</td>\n",
       "      <td>0.040636</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.040290</td>\n",
       "      <td>0.040636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>0.015320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.056378</td>\n",
       "      <td>0.052826</td>\n",
       "      <td>0.056378</td>\n",
       "      <td>0.056378</td>\n",
       "      <td>0.052826</td>\n",
       "      <td>0.056378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.027225</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>0.027225</td>\n",
       "      <td>0.027225</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>0.027225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.012353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10898347</td>\n",
       "      <td>0.046758</td>\n",
       "      <td>0.046831</td>\n",
       "      <td>0.046758</td>\n",
       "      <td>0.046758</td>\n",
       "      <td>0.046831</td>\n",
       "      <td>0.046758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10933547</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.020817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10940747</td>\n",
       "      <td>0.035597</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>0.035597</td>\n",
       "      <td>0.035597</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>0.035597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10954547</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>0.014082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10976347</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.015695</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.015695</td>\n",
       "      <td>0.015641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11073947</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.027427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11114347</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.027201</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.027201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11116947</td>\n",
       "      <td>-0.012063</td>\n",
       "      <td>-0.005490</td>\n",
       "      <td>-0.011976</td>\n",
       "      <td>-0.012063</td>\n",
       "      <td>-0.005490</td>\n",
       "      <td>-0.011976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11142747</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.021588</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.021588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11193347</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.020719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11215747</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.004496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11229347</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>-0.005910</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>-0.005910</td>\n",
       "      <td>-0.008836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11287347</td>\n",
       "      <td>0.035609</td>\n",
       "      <td>0.037460</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>0.035609</td>\n",
       "      <td>0.037460</td>\n",
       "      <td>0.037392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11288547</td>\n",
       "      <td>0.074797</td>\n",
       "      <td>0.077159</td>\n",
       "      <td>0.077455</td>\n",
       "      <td>0.074797</td>\n",
       "      <td>0.077159</td>\n",
       "      <td>0.077455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11324547</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11391347</td>\n",
       "      <td>0.025447</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.025447</td>\n",
       "      <td>0.025447</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.025447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11395747</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>0.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11404347</td>\n",
       "      <td>0.018830</td>\n",
       "      <td>0.018776</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.018830</td>\n",
       "      <td>0.018776</td>\n",
       "      <td>0.018843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11405747</td>\n",
       "      <td>0.013612</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.013612</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.015361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11417147</td>\n",
       "      <td>0.044757</td>\n",
       "      <td>0.046574</td>\n",
       "      <td>0.046494</td>\n",
       "      <td>0.044757</td>\n",
       "      <td>0.046574</td>\n",
       "      <td>0.046494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11457547</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>0.026390</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>0.026390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11488147</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.011533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11520747</td>\n",
       "      <td>0.033932</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.033932</td>\n",
       "      <td>0.033932</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.033932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11524947</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11544747</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.007385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985187</th>\n",
       "      <td>167636430</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985188</th>\n",
       "      <td>167690630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985189</th>\n",
       "      <td>167636630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985190</th>\n",
       "      <td>10834030</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985191</th>\n",
       "      <td>167637430</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985192</th>\n",
       "      <td>167637630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985193</th>\n",
       "      <td>167637230</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985194</th>\n",
       "      <td>11645030</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985195</th>\n",
       "      <td>167689030</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985196</th>\n",
       "      <td>167638630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985197</th>\n",
       "      <td>167638430</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985198</th>\n",
       "      <td>14342030</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985199</th>\n",
       "      <td>167638230</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985200</th>\n",
       "      <td>167637830</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985201</th>\n",
       "      <td>167639230</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985202</th>\n",
       "      <td>14341030</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985203</th>\n",
       "      <td>14341630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985204</th>\n",
       "      <td>14367630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985205</th>\n",
       "      <td>167638830</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985206</th>\n",
       "      <td>12572230</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985207</th>\n",
       "      <td>14460030</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985208</th>\n",
       "      <td>14284830</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985209</th>\n",
       "      <td>14285230</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985210</th>\n",
       "      <td>14455630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985211</th>\n",
       "      <td>11117630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985212</th>\n",
       "      <td>168176230</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985213</th>\n",
       "      <td>14273630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985214</th>\n",
       "      <td>168040630</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985215</th>\n",
       "      <td>168040830</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985216</th>\n",
       "      <td>168040430</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-0.020817</td>\n",
       "      <td>-0.018931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2985217 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ParcelId    201610    201611    201612    201710    201711    201712\n",
       "0         10754147  0.041009  0.040290  0.040636  0.041009  0.040290  0.040636\n",
       "1         10759547  0.015692  0.015001  0.015320  0.015692  0.015001  0.015320\n",
       "2         10843547  0.056378  0.052826  0.056378  0.056378  0.052826  0.056378\n",
       "3         10859147  0.027225  0.024866  0.027225  0.027225  0.024866  0.027225\n",
       "4         10879947  0.012353  0.012431  0.012353  0.012353  0.012431  0.012353\n",
       "5         10898347  0.046758  0.046831  0.046758  0.046758  0.046831  0.046758\n",
       "6         10933547  0.020817  0.020870  0.020817  0.020817  0.020870  0.020817\n",
       "7         10940747  0.035597  0.035945  0.035597  0.035597  0.035945  0.035597\n",
       "8         10954547  0.013484  0.013613  0.014082  0.013484  0.013613  0.014082\n",
       "9         10976347  0.015641  0.015695  0.015641  0.015641  0.015695  0.015641\n",
       "10        11073947  0.027427  0.027502  0.027427  0.027427  0.027502  0.027427\n",
       "11        11114347  0.027573  0.031200  0.027201  0.027573  0.031200  0.027201\n",
       "12        11116947 -0.012063 -0.005490 -0.011976 -0.012063 -0.005490 -0.011976\n",
       "13        11142747  0.021961  0.025578  0.021588  0.021961  0.025578  0.021588\n",
       "14        11193347  0.021389  0.025272  0.020719  0.021389  0.025272  0.020719\n",
       "15        11215747  0.005239  0.008362  0.004496  0.005239  0.008362  0.004496\n",
       "16        11229347 -0.008836 -0.005910 -0.008836 -0.008836 -0.005910 -0.008836\n",
       "17        11287347  0.035609  0.037460  0.037392  0.035609  0.037460  0.037392\n",
       "18        11288547  0.074797  0.077159  0.077455  0.074797  0.077159  0.077455\n",
       "19        11324547  0.004137  0.004180  0.004137  0.004137  0.004180  0.004137\n",
       "20        11391347  0.025447  0.020969  0.025447  0.025447  0.020969  0.025447\n",
       "21        11395747  0.013423  0.008438  0.010687  0.013423  0.008438  0.010687\n",
       "22        11404347  0.018830  0.018776  0.018843  0.018830  0.018776  0.018843\n",
       "23        11405747  0.013612  0.015289  0.015361  0.013612  0.015289  0.015361\n",
       "24        11417147  0.044757  0.046574  0.046494  0.044757  0.046574  0.046494\n",
       "25        11457547  0.025866  0.025917  0.026390  0.025866  0.025917  0.026390\n",
       "26        11488147  0.011533  0.011875  0.011533  0.011533  0.011875  0.011533\n",
       "27        11520747  0.033932  0.033494  0.033932  0.033932  0.033494  0.033932\n",
       "28        11524947  0.005638  0.005691  0.005638  0.005638  0.005691  0.005638\n",
       "29        11544747  0.006849  0.007446  0.007385  0.006849  0.007446  0.007385\n",
       "...            ...       ...       ...       ...       ...       ...       ...\n",
       "2985187  167636430 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985188  167690630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985189  167636630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985190   10834030 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985191  167637430 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985192  167637630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985193  167637230 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985194   11645030 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985195  167689030 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985196  167638630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985197  167638430 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985198   14342030 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985199  167638230 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985200  167637830 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985201  167639230 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985202   14341030 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985203   14341630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985204   14367630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985205  167638830 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985206   12572230 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985207   14460030 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985208   14284830 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985209   14285230 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985210   14455630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985211   11117630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985212  168176230 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985213   14273630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985214  168040630 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985215  168040830 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "2985216  168040430 -0.019133 -0.020817 -0.018931 -0.019133 -0.020817 -0.018931\n",
       "\n",
       "[2985217 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df = subm_df.drop([10, 11], axis=1)\n",
    "subm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_df.to_csv('lgbm_no_out_monthly.csv', index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
